{"cells":[{"cell_type":"markdown","metadata":{"id":"GzDmH7N5glbZ"},"source":["# Training model in Google Colab\n"]},{"cell_type":"markdown","metadata":{"id":"nPkoVcPGglbb"},"source":["## Connect to Google Drive and set up the environment = installing the required packages for Detectron2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z-c3E1YoG-TS"},"outputs":[],"source":["# from google.colab import drive\n","\n","# drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pZFcxTetKK2I"},"outputs":[],"source":["# !python -m pip install pyyaml==5.1\n","# import sys, os, distutils.core\n","# !git clone 'https://github.com/facebookresearch/detectron2'\n","# dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n","# !python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n","# sys.path.insert(0, os.path.abspath('./detectron2'))\n","\n","# # !python -m pip install \"git+https://github.com/facebookresearch/detectron2.git\""]},{"cell_type":"markdown","metadata":{"id":"51OgA34_glbd"},"source":["## Importing all necessary libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rODuY7GrKLi4"},"outputs":[],"source":["import os\n","import cv2, random\n","import matplotlib.pyplot as plt\n","import torch, detectron2\n","\n","# !nvcc --version\n","TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n","CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n","print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n","print(\"detectron2:\", detectron2.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IpDEEUvMKPhP"},"outputs":[],"source":["from detectron2.utils.logger import setup_logger\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog, DatasetCatalog\n","from detectron2.data.datasets import register_coco_instances\n","\n","setup_logger()"]},{"cell_type":"markdown","metadata":{"id":"DMTJZQ8Qglbd"},"source":["## Loading the data\n","\n","- The data is in COCO format. The register_coco_instances function registers the datasets. The MetadataCatalog.get and DatasetCatalog.get functions retrieve the metadata and the dataset respectively. The results are printed at the end."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B9YoMOjsf41A"},"outputs":[],"source":["train_images = \"/home/james/Projects/Fenotypizace/data/annotations/Train/images\"\n","train_json = \"/home/james/Projects/Fenotypizace/data/annotations/Train/result.json\"\n","\n","test_images = \"/home/james/Projects/Fenotypizace/data/annotations/Test/images/\"\n","test_json = \"/home/james/Projects/Fenotypizace/data/annotations/Test/result.json\"\n","\n","register_coco_instances(\"my_trainset\", {}, train_json, train_images)\n","register_coco_instances(\"my_testset\", {}, test_json, test_images)\n","\n","metadata = MetadataCatalog.get(\"my_trainset\")\n","dataset_dicts = DatasetCatalog.get(\"my_trainset\")\n","metadata_test = MetadataCatalog.get(\"my_testset\")\n","dataset_dicts_test = DatasetCatalog.get(\"my_testset\")\n","\n","print(f\"\\n{metadata}\\n \\n{metadata_test}\")"]},{"cell_type":"code","source":["for d in random.sample(dataset_dicts, 5):\n","    img = cv2.imread(d[\"file_name\"])\n","    visualizer = Visualizer(img[:, :, ::-1], metadata=metadata, scale=0.5)\n","    vis = visualizer.draw_dataset_dict(d)\n","    plt.figure(figsize=(15, 13))\n","    plt.imshow(cv2.cvtColor((vis.get_image()[:, :, ::-1]), cv2.COLOR_BGR2RGB))\n","    plt.show()"],"metadata":{"id":"T7XAOyxeheCa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S_vUKRErglbe"},"source":["## Training the model\n","\n","- The get_cfg function is used to create a new configuration that holds default values for configurations.\n","- The merge_from_file function is then used to merge the values from a YAML file that contains the pre-defined configurations for the Mask R-CNN model.\n","- The configuration object is then customized for the specific training task.\n","- THe directory for the output is created if it doesn't exist. The model is then trained using the DefaultTrainer class."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WXzgyoxOgMm7"},"outputs":[],"source":["from detectron2.engine import DefaultTrainer\n","from detectron2.model_zoo import get_config\n","\n","cfg = get_cfg()\n","cfg.merge_from_file(\n","    model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",")\n","cfg.DATASETS.TRAIN = (\"my_trainset\",)\n","cfg.DATASETS.TEST = ()\n","cfg.DATALOADER.NUM_WORKERS = 4\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\n","    \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n",")\n","cfg.SOLVER.IMS_PER_BATCH = 8\n","cfg.SOLVER.BASE_LR = 0.00025\n","cfg.SOLVER.MAX_ITER = 1300\n","cfg.SOLVER.STEPS = []\n","cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n","cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n","\n","os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n","trainer = DefaultTrainer(cfg)\n","trainer.resume_or_load(resume=False)\n","trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"tQTJIWN4glbe"},"source":["## Display training curves using tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H2Fm-T2qCdrt"},"outputs":[],"source":["%reload_ext tensorboard\n","%load_ext tensorboard\n","%tensorboard --logdir output"]},{"cell_type":"markdown","metadata":{"id":"083jrdPHglbf"},"source":["## Test sample\n","\n","- cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7 sets the threshold for the prediction score. Only regions with a score above this threshold will be considered in the final prediction.\n","- predictor = DefaultPredictor(cfg) creates a predictor object using the defined configuration. This object can be used to make predictions on new data.\n","- print(inference_on_dataset(trainer.model, test_loader, test_evaluator)) performs inference on the test dataset using the trained model and the test data loader, evaluates the results using the test evaluator, and prints the results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b0PfI6DKgODx"},"outputs":[],"source":["cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n","cfg.DATASETS.TEST = (\"my_testset\",)\n","predictor = DefaultPredictor(cfg)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K8IOID8wgPgK"},"outputs":[],"source":["from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n","from detectron2.data import build_detection_test_loader\n","\n","test_evaluator = COCOEvaluator(\"my_testset\", cfg, False, output_dir=\"./output/\")\n","test_loader = build_detection_test_loader(cfg, \"my_testset\")\n","print(inference_on_dataset(trainer.model, test_loader, test_evaluator))"]},{"cell_type":"markdown","metadata":{"id":"r5NSDG3Wglbf"},"source":["## Visualize the predictions on the test sample"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"MLl6Tinw_ua3"},"outputs":[],"source":["from detectron2.utils.visualizer import ColorMode\n","\n","for d in random.sample(dataset_dicts_test, 12):\n","    im = cv2.imread(d[\"file_name\"])\n","    outputs = predictor(im)\n","    v = Visualizer(\n","        im[:, :, ::-1], metadata=metadata_test, scale=0.8, instance_mode=ColorMode.IMAGE\n","    )\n","    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","    plt.figure(figsize=(15, 13))\n","    plt.imshow(cv2.cvtColor(v.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Z9D9xKI_glbf"},"source":["## Save the model on specific directory in Google Drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qvYV9M6UnSeU"},"outputs":[],"source":["# import shutil\n","\n","# # Zdrojová cesta k souboru nebo složce\n","# source_path = \"/content/drive/Shareddrives/KIT ML/Fenotypizace - vzchazeni/Code/Final/1. Trays segmentation/output\"\n","\n","# # # Cílová cesta na Google disku\n","# destination_path = \"/content/output\"\n","\n","# # Kopírování souboru nebo složky\n","# shutil.copytree(source_path, destination_path)"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}