{"cells":[{"cell_type":"markdown","source":["# DESCRIPTION\n","\n","This code is used to convert images into numpy arrays so that they can be utilized in time series analysis.\n"],"metadata":{"id":"kC9M5GdGNdy0"}},{"cell_type":"markdown","source":["## input"],"metadata":{"id":"e2RQO28qP0cX"}},{"cell_type":"markdown","source":["\n","\n","*   Folder with images we want to process.\n"],"metadata":{"id":"b_hHEC8lP1tA"}},{"cell_type":"markdown","source":["## output\n","\n","*   .npy file with images in a sequence, we can specify the size of the sequence.\n","\n","*   .npy file with annotations, so we can determine whether the plant is frosty or not.\n","\n","* .npy file with image names."],"metadata":{"id":"aTqCoSeGP2Cs"}},{"cell_type":"markdown","source":["imports"],"metadata":{"id":"ExBrG0xpPde9"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"a6C42efTnU4T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712163750758,"user_tz":-120,"elapsed":34090,"user":{"displayName":"Jakub Vašák","userId":"08582463981854486728"}},"outputId":"b6be30ca-44a8-4765-8990-5570ff672bc1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting keras-tcn\n","  Downloading keras_tcn-3.5.0-py3-none-any.whl (13 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-tcn) (1.25.2)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from keras-tcn) (2.15.0)\n","Collecting tensorflow-addons (from keras-tcn)\n","  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (24.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (4.10.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (0.36.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (1.62.1)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (2.15.0)\n","Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->keras-tcn)\n","  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->keras-tcn) (0.43.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (3.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (3.0.2)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (2.1.5)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (3.2.2)\n","Installing collected packages: typeguard, tensorflow-addons, keras-tcn\n","Successfully installed keras-tcn-3.5.0 tensorflow-addons-0.23.0 typeguard-2.13.3\n","Mounted at /content/gdrive\n"]}],"source":["\n","import pandas as pd\n","\n","import numpy as np\n","\n","import os\n","\n","from matplotlib import image as imagelib\n","\n","import glob\n","\n","from PIL import Image\n","\n","import matplotlib.pyplot as plt\n","\n","drive_path = \"\"\n","kit_ml_dir = \"/KIT ML/Fenotypizace - vzchazeni\"\n","if os.path.isdir(\"/Volumes/GoogleDrive/Shared drives\"):\n","    drive_path = \"/Volumes/GoogleDrive/Shared drives\"\n","elif os.path.isdir(\"G:/Shared drives\"):\n","    drive_path = \"G:/Shared drives\"\n","elif not os.path.isdir(drive_path):\n","    from google.colab import drive\n","    drive.mount('/content/gdrive')\n","    drive_path = \"/content/gdrive/Shareddrives\""]},{"cell_type":"code","source":["# opraveno, Honza\n","save_path= drive_path+\"/KIT ML 2/Data/numpy/cropped64/\"\n","\n","#directory for input files\n","# data_dir = kit_ml_dir + \"/Model/Data, na kterých jsem zkoušel rozpoznání klíčení/\"\n","feno_dir = drive_path + \"/Fenotypizace/EA2021-01Ohnoutkova/\"\n","data_path = kit_ml_dir + \"/Data\"\n","# teoreticky vyměnit jen tuto složku\n","data_images_path = drive_path + \"/KIT ML 2\" + \"/Data/cropped64/\"\n","\n","annotation_file = \"EA2021_01.xlsx\"\n","#[10,11,13,14,15,17,40,41,44,45,46,48]\n","#12,\n","trays_train = [10,11,12,13,14,15,16,18,41,47]\n","trays_val = [17,40,42,44,45]\n","trays_test = [43,46,48]\n","\n","#length of the sliding window\n","n_time_steps = [3,4,5]\n","n_data_range = [3,4,5,7,9]\n","#step, we need to identify precisely the time when it emerges\n","slide_step = 1\n","\n","# v kódu vypustit toto\n","img_crop = 160\n","\n","#model hyper parameters\n","val_split = 0.2\n","num_epochs = 5\n","\n","#RGB\n","colors = 3\n","\n","#img_size\n","img_size = 64"],"metadata":{"id":"iiaQoUefj8wD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# FUNCTIONS"],"metadata":{"id":"T4i5i89DPiyM"}},{"cell_type":"markdown","metadata":{"id":"MFBF1hIpktOn"},"source":["#### load annotations"]},{"cell_type":"markdown","metadata":{"id":"s4oPFd2ektOo"},"source":["#### load files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wUR5jvPsktOp"},"outputs":[],"source":["def load_annotations(annotation_path, use_trays):\n","    emergence = pd.read_excel(annotation_path, sheet_name = \"Results - emergence\", usecols = \"B,C,D,G,H\")\n","    df = emergence.loc[emergence['tray_location'].isin(use_trays)]\n","    return df\n","\n","def load_annotations(annotation_path, use_trays):\n","    emergence = pd.read_excel(annotation_path, sheet_name = \"Results - emergence\", usecols = \"B,C,D,G,H\")\n","    df = emergence.loc[emergence['tray_location'].isin(use_trays)]\n","    return df\n","\n","def index_containing_substring(the_list, substring):\n","    for i, s in enumerate(the_list):\n","        if substring in s:\n","              return i\n","    return -1\n","\n","def load_from_dir(df, data_directory, crop_size,length):\n","    labels = np.array([])\n","    imgs_array = np.array([])\n","    previous_img = None\n","\n","    for index1, item in df.iterrows():\n","        well_id = str(item[\"well_id\"])\n","        well_id = well_id.replace(\"_\",\"-\")\n","        directory = data_directory  + \"Tray_\" + str(int(item[\"tray_location\"])) + \"/\" + well_id\n","        #print(directory)\n","        index = 0\n","        germ_class = 0\n","\n","        # I do not need all files, instead take emerged +- length files\n","        files = sorted(glob.glob(directory + \"/*.png\"))\n","        #print(item[\"time_of_first_occurence\"])\n","        if not isinstance(item[\"time_of_first_occurence\"], str) or item[\"time_of_first_occurence\"] == \"-\":\n","            continue\n","        emerged_index = index_containing_substring(files, item[\"time_of_first_occurence\"].split(\"_\")[1])\n","        ## toto je klíčové\n","        files_ranged = files[emerged_index-length:emerged_index+length] # tohel nám určuje rozsah\n","        #print(emerged_index)\n","        #print(len(files_ranged))\n","\n","        df_occurrence = item[\"time_of_first_occurence\"].split(\"_\")[1] + \".png\"\n","\n","        for filename in files_ranged:\n","            filename_occurrence = filename.split(\"_\")[2] + \".png\"\n","            if df_occurrence == filename_occurrence:\n","                germ_class = 1\n","\n","            # we need images of the same size\n","            np_image = np.array(Image.open(filename))\n","            #np_image = imagelib.imread(filename)\n","            # print(np_image.shape)\n","            # print(root)\n","\n","            # if the image is smaller - probably corrupted\n","            if np_image.shape[0] < img_size or np_image.shape[1] < img_size:\n","                np_image = previous_img\n","                print(\"Image error:\"+filename)\n","            else:\n","                previous_img = np_image\n","\n","            #print(np_image.shape)\n","\n","            #add image to output array\n","            if len(imgs_array) == 0:\n","                imgs_array = np.array([np_image])\n","            else:\n","                imgs_array = np.append(imgs_array, [np_image], axis=0)\n","\n","            #output labels array\n","            if len(labels) == 0:\n","                labels = np.array([germ_class])\n","            else:\n","                labels = np.append(labels, [germ_class], axis=0)\n","\n","        index += 1\n","\n","    print(imgs_array.shape)\n","    print(labels.shape)\n","    return imgs_array, labels\n","\n","from matplotlib import image as imagelib\n","import glob\n","from PIL import Image\n","\n","def index_containing_substring(the_list, substring):\n","    for i, s in enumerate(the_list):\n","        if substring in s:\n","              return i\n","    return -1\n","\n","def load_from_dir_test(df, data_directory, crop_size,length):\n","    labels = np.array([])\n","    imgs_array = np.array([])\n","    image_names = []\n","    previous_img = None\n","\n","    for index1, item in df.iterrows():\n","        well_id = str(item[\"well_id\"])\n","        well_id = well_id.replace(\"_\",\"-\")\n","        directory = data_directory  + \"Tray_\" + str(int(item[\"tray_location\"])) + \"/\" + well_id\n","        index = 0\n","        germ_class = 0\n","\n","        # I do not need all files, instead take emerged +- length files\n","        files = sorted(glob.glob(directory + \"/*.png\"))\n","        #print(item[\"time_of_first_occurence\"])\n","        if not isinstance(item[\"time_of_first_occurence\"], str) or item[\"time_of_first_occurence\"] == \"-\":\n","            continue\n","        emerged_index = index_containing_substring(files, item[\"time_of_first_occurence\"].split(\"_\")[1])\n","        ## toto je klíčové\n","        files_ranged = files #PRY TO MA BYT ZAKOMENTOAVNE, JA TO UPRAVIL, ŽE TO VEZME VŠECHNY OBRÁZKY VE SLOŽCE, TAKŽE LENGTH ANRGUMENT JE IRELEVANTNÍ\n","        #print(emerged_index)\n","        #print(len(files_ranged))\n","\n","        df_occurrence = item[\"time_of_first_occurence\"].split(\"_\")[1] + \".png\"\n","\n","        for filename in files_ranged:\n","            filename_occurrence = filename.split(\"_\")[2] + \".png\"\n","            if df_occurrence == filename_occurrence:\n","                germ_class = 1\n","\n","            # we need images of the same size\n","            np_image = np.array(Image.open(filename))\n","            #np_image = imagelib.imread(filename)\n","            # print(np_image.shape)\n","            # print(root)\n","\n","            # if the image is smaller - probably corrupted\n","            if np_image.shape[0] < img_size or np_image.shape[1] < img_size:\n","                np_image = previous_img\n","                print(\"Image error:\"+filename)\n","            else:\n","                previous_img = np_image\n","\n","            #print(np_image.shape)\n","\n","            #add image to output array\n","            if len(imgs_array) == 0:\n","                imgs_array = np.array([np_image])\n","            else:\n","                imgs_array = np.append(imgs_array, [np_image], axis=0)\n","\n","            #output labels array\n","            if len(labels) == 0:\n","                labels = np.array([germ_class])\n","            else:\n","                labels = np.append(labels, [germ_class], axis=0)\n","\n","            image_names.append(os.path.basename(filename))\n","\n","        index += 1\n","\n","    print(imgs_array.shape)\n","    print(labels.shape)\n","    return imgs_array, labels, image_names\n","\n","\n","def generate_samples_test(images, labels, image_names, step, time_steps):\n","    img_trays = np.array([images[0:time_steps]])\n","    annotations_array = np.array([0])\n","    image_names_trays = np.array([image_names[0:time_steps]])\n","\n","    for i in range(1, images.shape[0] - time_steps, step):\n","        # if all items in a sliding window are equal, we use them for training\n","        # arr = labels[i:i + time_steps]\n","        # if np.all(arr == arr[0]):\n","        img_trays = np.append(img_trays, [images[i:i + time_steps]], 0)\n","        annotations_array = np.append(annotations_array, [labels[i]], 0)\n","        image_names_trays = np.append(image_names_trays, [image_names[i:i + time_steps]], 0)\n","\n","    print(img_trays.shape)\n","    return img_trays, annotations_array, image_names_trays\n","\n","def generate_samples(images, labels, step, time_steps):\n","    img_trays = np.array([images[0:time_steps]])\n","    annotations_array = np.array([0])\n","\n","    for i in range(1,  images.shape[0]- time_steps, step):\n","        #if all items in a sliding window are equal than we use them for training\n","        arr= labels[i:i + time_steps]\n","        if np.all(arr == arr[0]):\n","            img_trays = np.append(img_trays,[images[i:i+time_steps]],0)\n","            annotations_array = np.append(annotations_array, [labels[i]], 0)\n","\n","    print(img_trays.shape)\n","    return img_trays, annotations_array\n","\n","\n","# load data from file system and save it as numpy file\n","def load_data_images(images_path,annotations_path, use_trays, dataset =\"train\",sizes = 9, time_steps = 3, img_crop_size = 160):\n","    #load images from filesystem\n","    annotations_pd = load_annotations(annotations_path, use_trays)\n","\n","    #np.save(images_path +\"/\" + dataset + \"_raw_data_\"+str(size)+\"_\"+str(use_trays), raw_images)\n","    #np.save(images_path +\"/\" + dataset + \"_raw_annotations_\"+str(size)+\"_\"+str(use_trays), raw_annotations)\n","\n","    #generate samples\n","    for time_step in time_steps:\n","        print(\"step size: \"+str(time_step))\n","        # size není potřeba\n","        for size in sizes:\n","            if size<time_step: continue\n","            print (\"range size: \"+str(size))\n","            path = images_path +\"/npy_nonormalize/data_\"+str(time_step)+\"_\"+str(use_trays) + \".npy\"\n","            if os.path.isfile(path):\n","                print(\"exists\")\n","                continue\n","\n","            raw_images, raw_annotations = load_from_dir(annotations_pd, images_path, img_crop_size, size)\n","\n","            (samples, labels) = generate_samples(raw_images, raw_annotations,slide_step, time_step)\n","\n","            np.save(save_path + \"data_\"+ str(img_size) + \"_\" + str(time_step) + \"_\" + str(size) + \"_\" + str(use_trays), samples)\n","            np.save(save_path + \"annotations_\"+ str(img_size) + \"_\" + str(time_step) + \"_\" + str(size) + \"_\" + str(use_trays), labels)\n","\n","    return\n","\n","# load data from file system and save it as numpy file\n","def load_data_images_test(images_path,annotations_path, use_trays, dataset =\"train\",sizes = 9, time_steps = 3, img_crop_size = 160):\n","    # load images from filesystem\n","    annotations_pd = load_annotations(annotations_path, use_trays)\n","\n","    # generate samples\n","    for time_step in time_steps:\n","        print(\"step size: \" + str(time_step))\n","        for size in sizes:\n","            if size < time_step:\n","                continue\n","            print(\"range size: \" + str(size))\n","            path = images_path + \"/npy_nonormalize/data_\" + str(time_step) + \"_\" + str(use_trays) + \".npy\"\n","            if os.path.isfile(path):\n","                print(\"exists\")\n","                continue\n","\n","            raw_images, raw_annotations, image_names = load_from_dir_test(annotations_pd, images_path, img_crop_size, size)\n","\n","            (samples, labels, image_names_trays) = generate_samples_test(raw_images, raw_annotations, image_names, slide_step, time_step)\n","\n","            np.save(save_path + \"data_\" + str(img_size) + \"_\" + str(time_step) + \"_\" + str(size) + \"_\" + str(use_trays), samples)\n","            np.save(save_path + \"annotations_\" + str(img_size) + \"_\" + str(time_step) + \"_\" + str(size) + \"_\" + str(use_trays), labels)\n","            np.save(save_path + \"image_names_\" + str(img_size) + \"_\" + str(time_step) + \"_\" + str(size) + \"_\" + str(use_trays), image_names_trays)\n","\n","    return\n","\n"]},{"cell_type":"markdown","metadata":{"id":"weid1ceBktOr"},"source":["### Generate the samples - reorganize, take always batch of X images"]},{"cell_type":"markdown","source":["**It is necessary to change the paths where it will be saved, and we can also change the file name.**\n"],"metadata":{"id":"xGAu4lkPtiTo"}},{"cell_type":"markdown","metadata":{"id":"VMoJ6CL3nU4Z"},"source":["### Input parameters"]},{"cell_type":"markdown","source":["Here are the parameters we are using. In our case, we have data stored in multiple main folders and their subfolders, and our code has been adjusted accordingly."],"metadata":{"id":"CFllWsFKRG0K"}},{"cell_type":"markdown","source":["If you want to preprocess different data, you'll need to adjust the parameters significantly and likely modify the code as well."],"metadata":{"id":"lr6MeJb1RHMz"}},{"cell_type":"markdown","metadata":{"id":"GxISVYtQnU4a"},"source":["### load data"]},{"cell_type":"markdown","source":["# EXECUTION"],"metadata":{"id":"nZnlVUKpfmHb"}},{"cell_type":"code","source":["n_time_steps = [3]  # tady potřebujem pouze test set\n","n_data_range = [9]\n","#load_data_images(data_images_path,feno_dir+\"/\"+annotation_file,use_trays=trays_train,sizes=n_data_range, time_steps=n_time_steps, img_crop_size=img_crop)\n","#load_data_images(data_images_path,feno_dir+\"/\"+annotation_file,use_trays=trays_val,sizes=n_data_range, time_steps=n_time_steps, img_crop_size=img_crop)\n","load_data_images_test(data_images_path,feno_dir+\"/\"+annotation_file,use_trays=trays_test,sizes=n_data_range, time_steps=n_time_steps, img_crop_size=img_crop)\n","\n","\n","n_time_steps = [4]\n","n_data_range = [10]\n","load_data_images(data_images_path,feno_dir+\"/\"+annotation_file,use_trays=trays_train,sizes=n_data_range, time_steps=n_time_steps, img_crop_size=img_crop)\n","load_data_images(data_images_path,feno_dir+\"/\"+annotation_file,use_trays=trays_val,sizes=n_data_range, time_steps=n_time_steps, img_crop_size=img_crop)\n","load_data_images_test(data_images_path,feno_dir+\"/\"+annotation_file,use_trays=trays_test,sizes=n_data_range, time_steps=n_time_steps, img_crop_size=img_crop)\n","\n","n_time_steps = [2]\n","n_data_range = [8]\n","load_data_images(data_images_path,feno_dir+\"/\"+annotation_file,use_trays=trays_train,sizes=n_data_range, time_steps=n_time_steps, img_crop_size=img_crop)\n","load_data_images(data_images_path,feno_dir+\"/\"+annotation_file,use_trays=trays_val,sizes=n_data_range, time_steps=n_time_steps, img_crop_size=img_crop)\n","load_data_images_test(data_images_path,feno_dir+\"/\"+annotation_file,use_trays=trays_test,sizes=n_data_range, time_steps=n_time_steps, img_crop_size=img_crop)"],"metadata":{"id":"x9tXP_fUm-WE"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.15"}},"nbformat":4,"nbformat_minor":0}